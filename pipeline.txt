아래 예시는 CLI 명령어를 전부 Python API 호출로 치환한 “끝판왕” 스크립트입니다.
한 파일(train_pipeline.py)로 합쳐도 되고, 단계별로 나눠도 무방합니다.

0. 필수 패키지 설치 (한 번만)
python
복사
# 첫 실행 또는 가상환경 재구성 시
import subprocess, sys
subprocess.run([sys.executable, "-m", "pip", "install", "-U",
                "ultralytics",   # YOLO v11 core
                "sahi",          # Sliced Inference
                "wandb"])        # 선택·모니터링
Ultralytics 패키지는 YOLO 클래스와 convert_coco, export 등을 모두 포함합니다. 
Ultralytics Docs

1. (선택) AGAR 데이터셋 COCO → YOLO 변환
python
복사
from ultralytics.data.converter import convert_coco

# COCO json이 들어 있는 폴더 경로
convert_coco(labels_dir="agar/annotations",
             save_dir="agar/yolo_labels",
             use_segments=False)     # detection용이므로 세그먼트 불필요
Ultralytics Docs

2. 데이터 YAML 정의
python
복사
from pathlib import Path
import yaml, textwrap

dataset_root = Path("dataset")             # images/, labels/ 2‑계층 폴더
yaml_dict = dict(
    path=str(dataset_root),
    train="images/train",
    val="images/val",
    test="images/test",
    nc=1,
    names=["colony"]
)
(Path("colony.yaml")).write_text(textwrap.dedent(yaml.dump(yaml_dict)))
3‑A. 사전학습(AGAR)
python
복사
from ultralytics import YOLO

model = YOLO("yolo11s.pt")   # COCO pre‑trained 가중치
results = model.train(
    task="detect",
    data="agar.yaml",
    epochs=120,
    imgsz=640,
    batch=32,
    lr0=0.01,
    warmup_epochs=3,
    optimizer="AdamW",
    cos_lr=True,
    project="colony_exp",
    name="agar_pretrain",
    exist_ok=False,
    tracker="wandb"
)
best_ag_weights = results.best  # best.pt 경로
CLI yolo ... 명령에 대응하는 완전 동등 호출입니다. 
Ultralytics Docs

3‑B. 사내 데이터 파인튜닝
python
복사
finetune = YOLO(best_ag_weights)
results_ft = finetune.train(
    task="detect",
    data="colony.yaml",
    epochs=60,
    imgsz=640,
    batch=24,
    lr0=0.002,
    freeze=10,         # 백본 일부 동결
    project="colony_exp",
    name="finetune_run",
    exist_ok=False
)
4. 검증 및 통계 출력
python
복사
stats = finetune.val(
    data="colony.yaml",
    plots=True,            # PR, F1 곡선 저장
    save_json=True         # COCO‑style 결과 json
)
print(stats.results_dict)  # mAP50, mAP50‑95 등
5. 단일/배치 추론
python
복사
pred = finetune.predict(
    source="samples/plate.jpg",   # str 또는 Path / 폴더 / glob / url / webcam
    conf=0.25,
    iou=0.5,
    save=True,                    # 결과 이미지 저장
)
6. SAHI 슬라이스 추론 (초고해상도·소형 객체용)
python
복사
from sahi.models.yolov8 import Yolov8DetectionModel   # v11도 동일 인터페이스
from sahi.predict import get_sliced_prediction

detection_model = Yolov8DetectionModel(
    model_path=finetune.ckpt_path,   # 또는 'best.pt'
    confidence_threshold=0.25,
    device="cuda:0"                  # CPU 사용 시 'cpu'
)
result = get_sliced_prediction(
    image="samples/large_plate.jpg",
    detection_model=detection_model,
    slice_height=640,
    slice_width=640,
    overlap_height_ratio=0.2,
    overlap_width_ratio=0.2
)
result.export_visuals(export_dir="sahi_vis/")
Ultralytics Docs

7. TensorRT 엔진 내보내기 (Jetson Orin 등)
python
복사
engine_path = finetune.export(
    format="engine",           # ONNX → TensorRT
    device=0                   # GPU index
)
print(f"TensorRT engine saved to {engine_path}")
Ultralytics Docs
Ultralytics Docs

8. 추가 유틸리티 모음
python
복사
# (1) 데이터셋 통계만 빠르게 보고 싶을 때
from ultralytics.data.utils import yaml_check
yaml_check("colony.yaml")    # 클래스·라벨 통계 표 출력

# (2) 벤치마크 FPS
fps = finetune.benchmark(source="samples/webcam.mp4", imgsz=640, device=0)
print(f"Avg FPS: {fps:.2f}")

# (3) 시드 고정 (재현성)
import torch, random, numpy as np
seed = 42
torch.manual_seed(seed);  random.seed(seed);  np.random.seed(seed)
이렇게 쓰세요
**train_pipeline.py**로 저장 후 python train_pipeline.py 실행.

dataset/·agar/ 경로만 실제 폴더 위치에 맞게 수정.

WANDB나 TensorBoard로 로그를 확인하면 CLI 사용 때와 동일한 그래프를 얻을 수 있습니다.

위 스크립트는 모든 CLI 명령을 100 % 동일한 기능의 Python 함수 호출로 치환한 것으로,
추가 셸 명령어 없이 Jupyter/IDE 환경에서도 쉽게 재사용할 수 있습니다. 👍